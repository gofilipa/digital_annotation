<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2019-11-07 Thu 22:53 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Filipa  Calado" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orga829fde">1. Outline</a>
<ul>
<li><a href="#org330d4d1">1.1. Intro</a>
<ul>
<li><a href="#orgefebee3">1.1.1. Expand active reading to include affect</a></li>
<li><a href="#orgcdd1d0d">1.1.2. Dev Environment</a></li>
</ul>
</li>
<li><a href="#orgf22fc4e">1.2. Edtech</a>
<ul>
<li><a href="#org15463e8">1.2.1. Edtech tracks and standardizes learning</a></li>
<li><a href="#orgf9fc290">1.2.2. Fired Up</a></li>
<li><a href="#orgeed914d">1.2.3. The tension between the “provocative” and the “prescriptive”.</a></li>
<li><a href="#orga248bff">1.2.4. adder.html</a></li>
<li><a href="#org26dd3e1">1.2.5. Ponder</a></li>
<li><a href="#orgfc0b634">1.2.6. Lacuna Stories</a></li>
<li><a href="#org280db9b">1.2.7. Annotation Dashboard</a></li>
<li><a href="#orgeb09383">1.2.8. Styling the Dropdown IV:</a></li>
<li><a href="#orgd08941d">1.2.9. Quantifying Tension</a></li>
</ul>
</li>
<li><a href="#orgf0e420e">1.3. Layering Emotions</a>
<ul>
<li><a href="#orgb890452">1.3.1. Layering Colors / misfittings</a></li>
<li><a href="#orgf383e85">1.3.2. Tracing the Click</a></li>
<li><a href="#orgc2ce11f">1.3.3. How I Use Color: Engaging Emotions</a></li>
<li><a href="#orgc2c1abb">1.3.4. index.coffee</a></li>
<li><a href="#orgc791ec7">1.3.5. Damasio: Embodied Cognition</a></li>
</ul>
</li>
<li><a href="#org248060e">1.4. To Write: Color Theory toward a Queer Theory</a>
<ul>
<li><a href="#orge226951">1.4.1. Prescribed or spontaneous colors?</a></li>
<li><a href="#org78dbb9d">1.4.2. What can queer theory add to DH methodologies? How can we enable “Touching without Touching”</a></li>
</ul>
</li>
<li><a href="#org8a34ede">1.5. Works Cited</a></li>
<li><a href="#orgcb4ce5b">1.6. Resources</a>
<ul>
<li><a href="#org6cb191a">1.6.1. Meeting notes:</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org597a189">2. bank</a></li>
</ul>
</div>
</div>
<div id="outline-container-orga829fde" class="outline-2">
<h2 id="orga829fde"><span class="section-number-2">1</span> Outline</h2>
<div class="outline-text-2" id="text-1">
<p>
<i>The idea is that I bastardize my previous paper, interweave my dev notes as a narrative, make some proposals for using color, and
culminate in a conclusion about next steps.</i>
</p>
</div>

<div id="outline-container-org330d4d1" class="outline-3">
<h3 id="org330d4d1"><span class="section-number-3">1.1</span> Intro</h3>
<div class="outline-text-3" id="text-1-1">
</div>
<div id="outline-container-orgefebee3" class="outline-4">
<h4 id="orgefebee3"><span class="section-number-4">1.1.1</span> Expand active reading to include affect</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
This project explores digital annotation as a way to make solitary
reading practices more embodied and engaging. I modified an existing
annotation tool to use in my <i>English 220: Introduction to Writing
about Literature</i> course at Hunter College. As any English instructor
of lower-level undergraduate classes knows, close reading skills do
not come naturally to most readers, and have to be cultivated through
repeated modeling and practice. Instructors must make visible the
attention to language required in close reading, and demonstrate how
to analyze language in depth, particularly the elaboration of meaning
or significance. From my experience, I’ve found that using a digital
annotation tool&#x2013;particularly <i>Hypothes.is</i><sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup>&#x2013;in the classroom is
immensely helpful for modeling “active reading” strategies for
students and following their progress as they complete the reading. By
annotating passages as a class, I can guide them toward making
incisive and thoughtful responses; and by having them annotate the
text as homework, I am able to see what my students are thinking
about, how they incorporated their knowledge of figurative language
that we learned in class, and how they work towards making critical
arguments about their reading.
a
While this tool has been immensely helpful for teaching close and
critical attention to language, it can also encourage a limited and
mechanized way for responding to texts. In the textual comments, I see
that students tend to replicate each other's response structure,
turning whatever prompt or instructions I've given them into a rote
analytical exercise. 
</p>

<p>
[INSERT IMAGES OF ANNOTATIONS]
</p>

<p>
I wonder how a digital annotation tool might short circuit this habit
of response to address more directly the emotional and instinctual
reactions that occur during reading. To that end, I've modified my
<i>Hypothes.is</i> annotation tool to include a multi-color highlighter,
rather than just yellow. The option for multiple colors, I hope,
will expand "active reading" to include affect.
</p>

<p>
I'm interested in how this technological tool might recuperate the
role of the body in reading. The option for multi-color highlighting
prioritizes nonverbal or preverbal responses to recast reading as an
embodied activity, allowing students to confront their more immediate
responses, feelings, and gut reactions during the reading process. In
doing so, students may begin to see how their feelings are part of a
larger, more formalized analytical process. Katherine Hayles traces
the severance of the body from the mind, how "information lost its
body," across technological discourses (2). According to Hayles, the
prioritization of rationality over emotion emerges in eighteenth
century liberal humanist ideas about knowledge existing independently
of the body and extends to 20th and 21st century ideas about the
posthuman that imagine the body as a (detachable) prosthesis of the
mind. How can digital annotation can activate reading as an embodied
practice, connecting more directly to knowledge as feeling and affect,
rather than knowledge as information that exists purely in a textual
form?
</p>

<p>
In thinking about technology and embodiment, I'm also interested in
the parallels across the technical and neurological. In what follows,
I couch pedagogial interventions within discussions about how emotion
functions in the body, combinding discourses of educational technology
with neuroscience. Throughout this discussion, I also interweave a
narrative of the tool’s technical development, inserting images and
excerpts from my daily development notes. My aim here is to make the
coding work simultaneously more visible and opaque, indicating to the
nontechnical reader some of the suspensions of knowledge that are part
of immersing yourself within a technical project.
</p>
</div>
</div>

<div id="outline-container-orgcdd1d0d" class="outline-4">
<h4 id="orgcdd1d0d"><span class="section-number-4">1.1.2</span> Dev Environment</h4>
<div class="outline-text-4" id="text-1-1-2">
<p>
<i>3.1.19: Day One at the New Media Lab.</i>
</p>

<p>
<i>Today Joe and I tried following the Client development instructions on the H docs. There were a bunch of issues, mostly to do with NPM, which you can read about here and here. From what I can gather, Node requires you to install it globally. As a result, every time we ran NPM we encountered a bunch of errors.</i>
</p>

<p>
<i>It took us (mostly Joe!) about an hour and a half attempting to install the client and browser-extension this sloooow way before we finally doubled back and started over with a non-problematic installation of node. This involved deleting the repos from Github and starting over, installing the dependencies (node) via the NVM (node version manager) rather than NPM. The instructions are below:</i>
</p>

<p>
[IMAGE OF DEVENV.PNG]
</p>
</div>
</div>
</div>


<div id="outline-container-orgf22fc4e" class="outline-3">
<h3 id="orgf22fc4e"><span class="section-number-3">1.2</span> Edtech</h3>
<div class="outline-text-3" id="text-1-2">
</div>
<div id="outline-container-org15463e8" class="outline-4">
<h4 id="org15463e8"><span class="section-number-4">1.2.1</span> Edtech tracks and standardizes learning</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
This color-coding feature aims to resist the pervasive and insidious
nature of many “edtech” (or Educational Technology) tools and
platforms, especially those that quantify or “measure” student
learning. Audrey Watters explains that collecting information on
students not only makes them vulnerable to those who would profit from
them economically, but also reduces them to data points and labels,
such as “cheat” or “at risk” ("Ed Tech and Trump"). By reducing the
differences among learners, data collection and analytics&#x2013;which
purport to create “personalized” learning experiences&#x2014;actually work
to standardize and automate education. More recently, primary schools
in China have started to roll out a "smart learning" program, where
teachers track student learning through headbands that read brain
activity. The results of their neuronal activity is visualized so the
stduents can compete against each other:
</p>

<blockquote>
<p>
The competition plays out in the form of a simulated rocket race on a
screen at the front of the classroom. The headwear measures electric
signals from neurons in the brain and translates that into an
attention score using an algorithm. The more focused a student is, the
higher the score gets, and the higher his or her rocket flies. If the
score falls—meaning the student’s attention is waning—the rocket
slows. Wang et al, "China’s Efforts"
</p>
</blockquote>

<p>
This development of "smart learning" in China is part of a larger
trend of surveillance (and especially facial recognition technologies)
that is much more pervasive and advanced than in the US, at least for
the time being. China's example offers a glimpse of where the the
trajectory of edtech tools will eventually lead&#x2014;to mass and total
(neuronal) surveillance.
</p>
</div>
</div>

<div id="outline-container-orgf9fc290" class="outline-4">
<h4 id="orgf9fc290"><span class="section-number-4">1.2.2</span> Fired Up</h4>
<div class="outline-text-4" id="text-1-2-2">
<p>
10 years ago, Sharona Levy pointed out that, in English classes,
“there is no mechanism to open [our student's] heads and see which
neurons are firing while they are reading" (5). Things have changed
dramatically, but Levy's point&#x2014;that it is very difficult to
understand how a student processes a text&#x2014;still stands. The fact is
that neuroscientists are still in disagreement about seemingly simple
questions like where consciousness is located in the brain or body,
not to mention how learning functions on a neuronal level. This
uncertainty leaves a space for brain functioning to be coopted in
discourses about productivity and management. For example, Philosopher
Catherine Malabou points out the common assumption in "neuronal
ideology" that brains should be made to conform and adapt to social
and economic needs. Malabou finds a troubling parallel between
discourses on "brain plasticity," which posits a flexible, developing
brain, and capital's need for docile, networked, and adaptable
workers. She suggests that people resist this understanding of "brain
plasticity" by exploring another valence of the word plastic that is
based off the noun <i>plastique</i>, which means "explosive."  Rather than
approach plastic as flexible, something that can be molded to fit
economic needs, plastic can be an agent for annihiliation and
creativity. Plasticity in this sense is a means of refusal to submit
to the managerial model, to resist complicity to capitalism. Malabou
suggests that "Perhaps we ought to relearn how to enrage ourselves, to
explode against a certain culture of docility, of amenity, of the
effacement of all conflict even as we live in a state of permanent
war" (79). Here, Malabou insists that affect&#x2013;particularly anger&#x2014;is
a tool for refusing expectations for docility and complicity. Her
exhortation to "enrage" ourselves points to a way that people can use
emotion to subvert pressures to be managed or conform to standards of
productivity.
</p>
</div>
</div>

<div id="outline-container-orgeed914d" class="outline-4">
<h4 id="orgeed914d"><span class="section-number-4">1.2.3</span> The tension between the “provocative” and the “prescriptive”.</h4>
<div class="outline-text-4" id="text-1-2-3">
<p>
Malabou's deployment of affect as a way of resisting productivity
guides my own approach. Through this digital annotation tool, I
experiment with reading to engage moments of emotional struggle and
insight, rather than measurable “learning outcomes”. By experimenting
with nonverbal, embodied reactions to reading, I hope to explore how
“tracking” can serve ends that are not exploitative, but
empowering. In developing my version of the tool, I wonder how
annotation might expand or reduce the quality of the student’s
engagement with the text. Here, I’m concerned in the tension between
what I call the “provocative”&#x2014;opening up the text to new
insights&#x2014;and the “prescriptive”&#x2014;limiting a student’s interaction
with the text to a predetermined set of choices or options for
responding. How do annotation tools create a standardized method or
process in responding to texts? More specifically, how do certain
features, such as colors, categories, or tags, for example, actually
limit the kinds of responses they could have without these prompts,
creating a confining structure for response?
</p>
</div>
</div>

<div id="outline-container-orga248bff" class="outline-4">
<h4 id="orga248bff"><span class="section-number-4">1.2.4</span> adder.html</h4>
<div class="outline-text-4" id="text-1-2-4">
<p>
<i>5.2.19: adder.html</i>
</p>

<p>
<i>This is the short html file for the buttons, both the "Annotate" and
"Highlight" button that pop up together once you make a text selection.</i> <i>I was able to make an additional buttons (which didn't
actually work when pressed) on the toolbar by duplicating the html within the file. It is important to note that on its own, my work in this file was never functional. In order for the buttons to work, I had to modify some javascript files that saved and passed the data from the user’s click.</i>
</p>

<p>
<i>The image shows two files on top of each other. In the background, there’s an image of my final modifications to the adder, with an additional drop down menu for colors under the “Highlight” button. In the foreground, there’s an image of the original HTML file that configured the adder.</i>
</p>
</div>
</div>


<div id="outline-container-org26dd3e1" class="outline-4">
<h4 id="org26dd3e1"><span class="section-number-4">1.2.5</span> Ponder</h4>
<div class="outline-text-4" id="text-1-2-5">
<p>
<a href="itp_final_images/ponder.png">ponder response options</a>
</p>

<p>
The annotation tool most compelling for my puposes is “Ponder”,
created by a private tech company, Parlor Labs, Inc.  Like
Hypothes.is, Ponder is a browser add-on tool that can be activated on
any webpage. The company describes it as a “micro-response tool”, that
purports to “give teachers a view into the ‘invisible’ process of
learning through higher-order critical thinking” (“About”). The tool
shares a basic functionality with Hypothes.is, which is highlighting
text and responding through a written annotation. But it has some
additional features, including options for different “reactions”,
called “sentiment tags”, and options for choosing from a list of
“themes”, compiled and customized by the teacher. The “sentiment tags”
are particularly interesting, because they allow students to
color-code their responses according to the categories
“clarification”, “analysis” or “emotion”. Carl Byth explains that goal
of this “microresponse” strategy is to condense student responses into
a simple expression that others can most easily engage with:
</p>

<blockquote>
<p>
To encourage students to “read each other,” Ponder limits responses
to short phrases called sentiments that fall into three categories:
comments about text comprehension (e.g., “I don’t get this”),
critiques of the text (e.g., “This smells like hyperbole”), and
emotional responses to the text (e.g., “Tsk, I disapprove.”) Blyth 209
</p>
</blockquote>

<p>
Here, the pithy annotations allow interpretations to be shared and
recognized among readers. These “microresponses” function analagously
to emoticons or emojis, which are more exaggerated methods of
condensing feeling into a expression that’s easily shared across
social media. 
</p>

<p>
Despite the obvious social benefits of this tool, this
prefabrication of responses seems constraining. By forcing the reader
to choose between “clarification”, “analysis” or “emotion”, is the
tool determining what kind of reaction someone might have? Or do these
three tagging option (the cognitive, analytic, or emotional) function
as an “enabling constraint”, that is, as a productive scaffolding that
guides students toward thinking more deeply about their reading?
Keeping these questions in mind, I now turn to another tool that
functions similarly to Ponder.
</p>
</div>
</div>

<div id="outline-container-orgfc0b634" class="outline-4">
<h4 id="orgfc0b634"><span class="section-number-4">1.2.6</span> Lacuna Stories</h4>
<div class="outline-text-4" id="text-1-2-6">
<p>
This other example of digital annotation comes from a project called
“Lacuna Stories," developed by the Poetic Media Lab at Stanford, where
it is deployed as a Learning Management System. As such, it is used by
schools like Stanford as a central organizing space for a course, like
Blackboard or Canvas, and provides a reading and writing interface for
engaging with course materials. The annotation here functions
similarly to Ponder: the reader highlights a section of the text, and
has the option of making a comment. Then, the reader is prompted by
options for different types of responses. Like Ponder, there are
pre-set categories for responding, which are also color-coded: here,
the categories are “Comment”, “Question”, “Analyze”, “Connect”. According to Stanford instructors Amir Eshel and Brian Johnsrud, one
of the tool’s main benefits is how it visualizes their students'
solitary responses to reading in a way that directs classroom
discussion about the text.
</p>

<p>
<a href="itp_final_images/lacuna.png">lacuna stories interface</a>
</p>
</div>
</div>

<div id="outline-container-org280db9b" class="outline-4">
<h4 id="org280db9b"><span class="section-number-4">1.2.7</span> Annotation Dashboard</h4>
<div class="outline-text-4" id="text-1-2-7">
<p>
<a href="itp_final_images/lacuna_dash.png">lacuna stories instructor dashboard</a>
</p>

<p>
Despite the benefits, there are drawbacks that come with increased
access to student annotations. Making annotations visible necessarily
prescribes certain patterns of response and textual interpretations
over others. The instructors admit that Lacuna creates a trade-off
between what they call “guidance and discovery”, that is, “a tension
that must be negotiated between the desire to allow students the space
for intellectual discovery and the desire to guide their learning
along a pre-specified path” (“Making Reading Visible”). This tension
emerges when the act of annotating primes students toward more fixed
interpretations of the text before they even enter into the
classroom. Another drawback is the way that Lacuna Stories tracks and
visualizes student activity across the platform. Lacuna contains an
“Annotation Dashboard,” that is only visible to instructors so that
they might access data about their students' annotations. On this
“Annotations Dashboard,” student data such as the number and length of
annotations is quantified and visualized in a series of graphs and
charts. Here, annotations "serve as an accountability mechanism for
completing assigned reading in a timely fashion, because instructors
will see students’ activity on the text and students will know that
instructors can see this activity” (schneider, Emily, et al,
PARAGRAPH). In the panel, “Filter by Time," instructors can view the
raw number of annotations made on any given day of the course, getting
a sense of daily participation. In “Annotation Details”, a series of
pie charts indicate the relative amount of annotations by category,
the length for each annotation, and the ratio of shared to
private. Finally, the “Network” section connects students to the texts
they have annotated, where the links between them are weighted
according to the amount of annotations each student made on each
text. By directly visualizing quantitative (rather than qualitative)
information about student annotations, the Annotation Dashboard
potentially engages in the reductive effects of certain edtech tools
that Audrey Watters warns about. Does tracking the length of each
annotation prioritize quantity of writing as an assessment criterion?
</p>
</div>
</div>

<div id="outline-container-orgeb09383" class="outline-4">
<h4 id="orgeb09383"><span class="section-number-4">1.2.8</span> Styling the Dropdown IV:</h4>
<div class="outline-text-4" id="text-1-2-8">
<p>
<b><b>Label-less Icons</b></b>: July 17, 2019: After much difficulty, I've
decided to forgo the color labels on the drop down, and have the
highlighter icon on its own, in the relevant color. When playing
around with different sizes for the icon, its simiplicity started to
appeal to me. This decision also accords with what I've said before
regarding Jon Udell's script to "tag" annotations with color. My
project is moving away from using verbal cues and engaging in verbal
reactions. So having the color itself be the selection on the
interface makes sense, because the person engages directly with that
color. The problem is that coloring the icons proved extremely time
consuming. I wanted each icon to display the color indicated in the
colors label. First, I spent a lot of time trying to find the source
of the icon to change the color, ended up going on icomoon, where I
still couldn't figure out how to do it. I also tried a bunch of
different CSS solutions, coloring the h-icon-highlight image to red,
for example. This worked, but it made all the icons red. There's no
way for me to do this just to one icon. I finally ended up by using in
inline CSS rule in adder.html to color the entire button. This is less
elegant than I hoped, but at this point I need to move on. I'm going
to leave it as is and start thinking about functionality.
</p>

<p>
<a href="itp_final_images/dropdown1.png">the first iteration: a boring dropdown menu</a>
<a href="itp_final_images/dropdown2.png">the second iteration: a busy style</a>
<a href="itp_final_images/dropdown3.png">the third iteration: simple colored icons</a>
</p>
</div>
</div>

<div id="outline-container-orgd08941d" class="outline-4">
<h4 id="orgd08941d"><span class="section-number-4">1.2.9</span> Quantifying Tension</h4>
<div class="outline-text-4" id="text-1-2-9">
<p>
There is a way that the tool uses quantified data in order to address
reading experiences that cannot be quantified. The visualization of
heavily annotated areas of text (in the “Network” panel) allows the
instructors to identify moments of collective interest within
annotations, and turn them back into sites of affect. The instructors
explain that, “By using Lacuna as a window into students’ reading,
[we] were able to pinpoint the exact places in the text that generated
the most frustration, confusion, or disagreement [among] students”
(“Making Reading Visible”). Here, the threaded annotations, where
students engage in debate and conversation about the text, serve as an
indicator of tension in their reading. Instructors can then turn the
class’s attention to exploring these moments more fully.
</p>
</div>
</div>
</div>

<div id="outline-container-orgf0e420e" class="outline-3">
<h3 id="orgf0e420e"><span class="section-number-3">1.3</span> Layering Emotions</h3>
<div class="outline-text-3" id="text-1-3">
</div>
<div id="outline-container-orgb890452" class="outline-4">
<h4 id="orgb890452"><span class="section-number-4">1.3.1</span> Layering Colors / misfittings</h4>
<div class="outline-text-4" id="text-1-3-1">
<p>
Identifying moments of tension is one of the goals of my multi-color
highlighter. The Hypothes.is highlighter contains a degree of opacity,
which can be adjusted manually by going into the code. In making the
colors almost transparent, one color can be layered over another,
creating color mixtures and combinations. I intend that the low
opacities of the highlighter colors will facilitate the layering of
one color over another, creating a visible palimpsest of
readings. This layering feature recalls conversations in neuroscience
about the ways that embodied cognition works within social
contexts. Although much of neuroscientific work on "embodied
cognition" does a good job situating thinking in the body, it tends to
overlook how body specificity determines individual
experience. According to Victoria Pitts-Taylor, much of this work
generalizes the way that everyone accesses and experiences the world,
assuming universal brain structures. In response, Pitts-Taylor
explores how brains are shaped by real inequalities of race, gender,
class, and sexuality, asserting that “bodily difference yields
cognitive difference” (56). She gives the example of "mirror neurons,"
which are neurons in the brain which activates both when we act and
when we see someone else engaged in an action. These neurons "mirror"
whatever action they perceive, representing the same process in the
brain as if the body were really performing the action, and are
therefore thought to enable empathy. According to Pitts-Taylor,
however, simulation can actually get in the way of
understanding. Bodily difference will cause mirror neurons to make
mistakes, projecting one set of assumptions onto another body. She
explains that “We cannot rely on simulation, whether propositional or
neural, to do the work of knowing the other and of relating to them
and feeling for them in nonviolent ways” (92). My tool aims to reveal
this limit of identification through the layering feature. It is my
hope that alternative reactions to a particular text will render in
the color mixtures, in the alchemy of dissonances, combinations, and
new concoctions that layering creates.
</p>
</div>
</div>

<div id="outline-container-orgf383e85" class="outline-4">
<h4 id="orgf383e85"><span class="section-number-4">1.3.2</span> Tracing the Click</h4>
<div class="outline-text-4" id="text-1-3-2">
<p>
/8.8.19 I spent some time trying to understand this process as a
whole, but since it's so big, I had to break it up. I outlined the
parts of the code relevant to highlighting (which Joe pointed out to
me). I was able to get a better sense of how the highlighting is
processed here, through specific functions and calls. Things really
started to come together when I followed the code backward, starting
from the end, and working my way up to the event handler in
adder.js. Overview of events: The onHighlight option called in
addder.js here initiates a call to createHighlight which passes "true"
for highlight into a larger function called createAnnotation. It's in
this function that highlightRange runs with potentially three
arguments, which I can configure in index.coffee. Joe suggested that I
pass a CSS class into this function as a third argument, which
specifies the color of the highlight. That's it!/
</p>
</div>
</div>

<div id="outline-container-orgc2ce11f" class="outline-4">
<h4 id="orgc2ce11f"><span class="section-number-4">1.3.3</span> How I Use Color: Engaging Emotions</h4>
<div class="outline-text-4" id="text-1-3-3">
<p>
One way to harness the color opacity is to have color mixtures
indicate emotions. Below, you see pictured a “wheel of emotions”
developed by Robert Plutchik, a professor of psychology, who
transposes his own theory of emotions into a color wheel. In this
image, the color differences indicate changes in emotional quality and
saturation indicates the intensity of emotion. The more saturated
colors on the inner ring represent more intense forms of the emotion,
while the brighter colors on the outer rings are milder. There are
eight primary emotions, which run along the second ring: these are
joy, trust, fear, surprise, sadness, disgust, anger and
anticipation. For example, apprehension (light green) is a mild form
of fear, while rage (dark red) is an intense form of anger. Plutchik
also theorized emotional dyads, which are feelings composed of two
emotions. You can see the dyad between fear and surprise, which is
awe, or between joy and trust, which is love.
</p>

<p>
I imagine that students might use these colors not only to highlight
text according to their feelings or gut reactions, but also to engage
with other students’ highlights in the form of layering. I wonder what
would happen, for example, if one student were to highlight a piece of
text as orange, for “anticipation”, and another were to highlight that
same piece as red, for “anger”. The resulting dyad, which would be
red-orange, signifies “aggressiveness” on the chart. How does this
result change the way we read the text? My sense is that confronting
and attending to these feelings will open up ways that students
connect to what they read.
</p>
</div>
</div>

<div id="outline-container-orgc2c1abb" class="outline-4">
<h4 id="orgc2c1abb"><span class="section-number-4">1.3.4</span> index.coffee</h4>
<div class="outline-text-4" id="text-1-3-4">
<p>
8.30.19 it works!
</p>

<p>
Last week, I had a meeting with Joe and we were able to iron out the
remaining issue of calling the highlight value from the button to
configure the highlight color. Basically, we passed the highlight data
through guest.coffee into the highlighter module, in index.coffee,
where we added a script that configures the appropriate color
depending on which button was clicked.
</p>
</div>
</div>

<div id="outline-container-orgc791ec7" class="outline-4">
<h4 id="orgc791ec7"><span class="section-number-4">1.3.5</span> Damasio: Embodied Cognition</h4>
<div class="outline-text-4" id="text-1-3-5">
<p>
This tool approaches affect as a type of knowledge that extends into
the body, and intends that the user interface will engage bodily
experience. The process of embodied cognition&#x2014;how thinking happens
with the body&#x2014;is therefore a crucial consideration to my
project. Neuroscientists have long disagreed over whether thinking
properly occurs in the brain, the body, or the world. Antonio Damasio,
a vocal proponent for embodied consciousness, explains that
consciousness arises from emotions in the body of the organism, which
are experienced as "somatic markers" such as rapid heartbeat or
nausea. These emotive experiences in the body float then up to an
organism's awareness, whereby rapid heartbeat might be noticed as
anxiety, and nausea as disgust. Damasio makes this key distinction
between emotion (in the body) and feeling (a mental awareness):
</p>

<blockquote>
<p>
Emotions are complex, largely automated programs of <i>actions</i>
concocted by evolution. The actions are complemented by a <i>cognitive</i>
program that includes certain ideas and modes of cognition, but the
world of emotions is largely one of actions carried out in our bodies,
from facial expressions and postures to changes in viscera and
internal milieu. Feelings of emotion, on the other hand, are composite
<i>perceptions</i> of what happens in our body and mind when we are
emoting. As far as the body is concerned, feelings are images of
actions rather than actions themselves; the world of feelings is one
of perceptions executed in brain maps. 116-117
</p>
</blockquote>

<p>
By the time a person is aware of a feeling, it has already released an
emoting cascade in the body. According to Damasio, our feelings are
often vague because their stimulation often incorporates internal,
largely unconscious sensations that he calls "primordial feelings" as
part of the emoting cascade (108). I intend for my tool to engage the
vagueness of embodied feelings by giving the body the opportunity to
interact with emotion haptically through the experience of using the
computer interface. My idea is that the user's activity of making a
text selection and choosing colors will create a rhythm of response
that harnesses immediate and primordial feelings that occur during the
reading process.
</p>
</div>
</div>
</div>

<div id="outline-container-org248060e" class="outline-3">
<h3 id="org248060e"><span class="section-number-3">1.4</span> To Write: Color Theory toward a Queer Theory</h3>
<div class="outline-text-3" id="text-1-4">
</div>
<div id="outline-container-orge226951" class="outline-4">
<h4 id="orge226951"><span class="section-number-4">1.4.1</span> Prescribed or spontaneous colors?</h4>
<div class="outline-text-4" id="text-1-4-1">
<p>
image: <a href="https://mymodernmet.com/color-mixing-chart/">https://mymodernmet.com/color-mixing-chart/</a> 
</p>

<p>
One of the challenges in developing the tool will be to think through
the affordances of using color in pre-defined ways and using it more
spontaneously.
</p>

<p>
Another will be to think through the choice of color palettes. Now, I
have chosen primary colors of red-blue-yellow, with low opacities, to
facilitate color layerings and the engendering of new colors. But
there are other options for colors. 
</p>

<p>
What if I chose color schemes that have other significations? For
example, the Trans flag, which comes in pink, blue, and white. How
would such a color scheme affect reading?
</p>

<p>
[image of trans flag].
</p>

<p>
What about other schemes, collections of triadic colors? 
</p>
</div>
</div>

<div id="outline-container-org78dbb9d" class="outline-4">
<h4 id="org78dbb9d"><span class="section-number-4">1.4.2</span> What can queer theory add to DH methodologies? How can we enable “Touching without Touching”</h4>
</div>
</div>

<div id="outline-container-org8a34ede" class="outline-3">
<h3 id="org8a34ede"><span class="section-number-3">1.5</span> Works Cited</h3>
<div class="outline-text-3" id="text-1-5">
<p>
Annotation Studio . Massachusetts Institute of Technology Hyperstudio.
<a href="http://www.annotationstudio.org/">http://www.annotationstudio.org/</a>
</p>

<p>
Bean, John. Engaging Ideas: The Professor's Guide to Integrating Writing, Critical Thinking,
and Active Learning in the Classroom . San Francisco: Jossey-Bass, 2001.
</p>

<p>
Blyth, Carl S. “Exploring the Affordances of Digital Social 201 Reading for L2 Literacy: The
Case of eComma” Digital Literacies in Foreign and Second Language . Ed. Janel Pettes
Guikema and Lawrence Williams, CALICO Monograph Series, Vol. 12. 2014
</p>

<p>
Hayles, N Katherine. How We Became Posthuman: Virtual Bodies in Cybernetics, Literature,
and Informatics . University of Chicago Press, 2010. Print.
</p>

<p>
Hypothes.is . The Hypothes.is Project. <a href="https://web.hypothes.is/">https://web.hypothes.is/</a>
</p>

<p>
Lacuna Stories . The Poetic Media Lab, Standford
University. <a href="https://www.lacunastories.com/">https://www.lacunastories.com/</a>
</p>

<p>
Levy, Sharona A., “Reading the Reader”. <i>The Difference the Enquiry Makes</i>. ed. Randy Bass and
Bret Enyon. Academic Commons, January 2009.
</p>

<p>
Malabou, Catherine.
</p>

<p>
Plutchik, R. "The Nature of Emotions." <i>American Scientist.</i> Archived from the original on July
16, 2001.
</p>

<p>
Ponder . Parlor Labs, Inc. <a href="https://www.ponder.co/about/">https://www.ponder.co/about/</a>
</p>

<p>
Schneider, Emily, et al. “Making Reading Visible: Social Annotation with Lacuna in the
Humanities Classroom.” The Journal of Interactive Technology and Pedagogy , 16 June
2016
</p>

<p>
Tai, Yifan Wang, Shen Hong and Crystal. “China’s Efforts to Lead the Way in AI Start in Its Classrooms.” Wall Street Journal, 24 Oct. 2019. www.wsj.com, <a href="https://www.wsj.com/articles/chinas-efforts-to-lead-the-way-in-ai-start-in-its-classrooms-11571958181">https://www.wsj.com/articles/chinas-efforts-to-lead-the-way-in-ai-start-in-its-classrooms-11571958181</a>.
</p>

<p>
Watters, Audrey. “ Ed-Tech and Trump .” Hack Education. February 2, 2017.
</p>
</div>
</div>


<div id="outline-container-orgcb4ce5b" class="outline-3">
<h3 id="orgcb4ce5b"><span class="section-number-3">1.6</span> Resources</h3>
<div class="outline-text-3" id="text-1-6">
<ul class="org-ul">
<li><a href="https://github.com/gofilipa/digital_annotation/blob/master/proposal_summary.md">Proposal Summary</a></li>
<li><a href="https://github.com/hypothesis/frontend-toolkit/blob/master/docs/css-style-guide.md">CSS Guide</a></li>
<li><a href="https://github.com/hypothesis/product-backlog/issues/198">Multiple Color issue on github</a></li>
<li><a href="https://www.w3.org/TR/annotation-model/">W3C Annotation Standards</a></li>
<li>Levy, Sharona A., “Reading the Reader”. The Difference the Enquiry Makes . ed. Randy Bass and</li>
</ul>
<p>
Bret Enyon. Academic Commons, January 2009.
</p>
</div>

<div id="outline-container-org6cb191a" class="outline-4">
<h4 id="org6cb191a"><span class="section-number-4">1.6.1</span> Meeting notes:</h4>
<div class="outline-text-4" id="text-1-6-1">
<p>
Michael:
</p>

<p>
Make my commit the best argument I can for why DH is an artist space.
</p>
<ul class="org-ul">
<li>Scholarship as code</li>
<li>Question: Currently we use different saturation values for our
highlight color when selections overlap each other. How will we
approach the overlapping of either completely different highlight
colors? Is there a theory of color blending? (DWHALEY)</li>
</ul>

<p>
Writing the paper
</p>
<ul class="org-ul">
<li>Think about where I can publish it. Hybrid pedagogy?</li>
<li>Find a way to bring in my development notes as a narrative of my
work.</li>
<li>Think about how the story ends: accepted or rejected? Using it in a</li>
</ul>
<p>
class? Scholarship as code? Accepted or rejected? What is the promise
of queer DH?
</p>

<p>
Color
</p>
<ul class="org-ul">
<li>My values / saturations are off.</li>
<li>Read up on Color Theory. What are some color meanings?</li>
<li>What are the right colors? What do they mean?</li>
<li>Imagine what colors I would use to annotate a Woolf text</li>
</ul>
</div>
</div>
</div>
</div>

<div id="outline-container-org597a189" class="outline-2">
<h2 id="org597a189"><span class="section-number-2">2</span> bank</h2>
<div class="outline-text-2" id="text-2">
<p>
The emphasis here on frustration and confusion enacts something
analogous to John Bean’s strategy of posing “beautiful problems” to
guide class writing and discussion. Bean suggests instructors organize
their lessons around “problems”, specifically, “beautiful problems…
[which] create natural critical learning environments” (3). He
explains that good writing assignments provoke a kind of productive
discomfort, and that academic writing ought to capitalize on this
“intellectual and often emotional struggle” (23). According to Bean,
this struggle emerges with the awareness that a problem exists, which
students must attempt to resolve. I’m interested in exploring how
“beautiful problems” create moments of insight and spontaneous
response.  Throughout his work, I’m most influenced by power that
“wonder”, “discomfort” and “struggle” have in stimulating
thinking. But unlike Bean, I dwell on the power of these affects prior
to their verbalization in traditional composition practices
</p>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><p class="footpara">
Hypothes.is operates as a browser extension and embeddable
script, which means that it can be activated and used on any page that
appears on a web browser. To use hypothes.is, the user must first
create an account on the Hypothes.is homepage. Then, they have two
options. They can either navigate to a website that already has
hypothes.is embedded and activated, or they can to download a browser
extension and activate it. Then, to make an annotation, users
highlight the desired text and type their comment in a simple text box
that appears. After saving their comment, the original text is
highlighted, and all users may view the annotation on a collapsible
sidebar. By selecting the “reply” button, users then can respond to
the comment, which will appear below the previous annotation on the
sidebar.
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Filipa  Calado</p>
<p class="date">Created: 2019-11-07 Thu 22:53</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
